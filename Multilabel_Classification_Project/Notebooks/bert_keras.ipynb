{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5YYUuqDExhP"
      },
      "source": [
        "**Multi-Label Text Classification Using BERT-Fine-Tuning (Toxic Comments Classification)**\n",
        "\n",
        "**Detailed Article**: https://pysnacks.com/bert-text-classification-with-fine-tuning\n",
        "\n",
        "Multi-class: https://colab.research.google.com/drive/1VuPv_SInihZIO9gwy1p0YqYQy76bwBuS\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgDBWnhbhhi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e76778c0-f458-4eac-8096-033f2dea8005"
      },
      "source": [
        "#@title Install libraries\n",
        "!pip install -q keras-bert keras-rectified-adam\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slKx6zy6EtyZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEG4MgX-h-YL"
      },
      "source": [
        "#@title Set environment variables\n",
        "import os\n",
        "import contextlib\n",
        "import tensorflow as tf\n",
        "\n",
        "USE_TPU = False\n",
        "os.environ['TF_KERAS'] = '1'\n",
        "\n",
        "# @title Initialize TPU Strategy\n",
        "if USE_TPU:\n",
        "  TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "  tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "  strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "import os\n",
        "import codecs\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Tensorflow Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.python import keras\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Keras-bert imports\n",
        "from keras_radam import RAdam\n",
        "from keras_bert import Tokenizer\n",
        "from keras_bert import get_custom_objects\n",
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "os.environ['TF_KERAS'] = '1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbsrd0q9wLso"
      },
      "source": [
        "#!wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\r\n",
        "#!unzip -o uncased_L-12_H-768_A-12.zip\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk6pgWDV5jxr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "2ded76df-7f18-45f5-f2c6-133b3f70314e"
      },
      "source": [
        "# @title Download models and data\n",
        "\n",
        "# Train/test Files\n",
        "test_datapath = 'test.csv'\n",
        "train_datapath = 'train.csv'\n",
        "\n",
        "# Bert Files\n",
        "pretrained_path = '%s/uncased_L-12_H-768_A-12'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "-rw------- 1 root root 68802655 Jan 18  2018 '/content/gdrive/My Drive/pysnacks/resources/datasets/jigsaw-toxic-comment-classification-challenge/train.csv'\n",
            "total 244926\n",
            "-rw------- 1 root root 55201987 Apr 11 14:16 jigsaw-toxic-comment-classification-challenge.zip\n",
            "-rw------- 1 root root  6279782 Jun 19  2018 sample_submission.csv\n",
            "-rw------- 1 root root  1459715 Dec 11 04:00 sample_submission.csv.zip\n",
            "-rw------- 1 root root 60354593 Jan 18  2018 test.csv\n",
            "-rw------- 1 root root 24577258 Dec 11 04:00 test.csv.zip\n",
            "-rw------- 1 root root  4976930 Jun 19  2018 test_labels.csv\n",
            "-rw------- 1 root root  1527605 Dec 11 04:00 test_labels.csv.zip\n",
            "-rw------- 1 root root 68802655 Jan 18  2018 train.csv\n",
            "-rw------- 1 root root 27619914 Dec 11 04:00 train.csv.zip\n",
            "total 430339\n",
            "-rw------- 1 root root       288 Feb 20 18:55 bert_config.json\n",
            "-rw------- 1 root root 440425712 Feb 20 18:57 bert_model.ckpt.data-00000-of-00001\n",
            "-rw------- 1 root root      8528 Feb 20 18:57 bert_model.ckpt.index\n",
            "-rw------- 1 root root    231508 Feb 20 18:57 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbDYv2Oth_gD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3d8f18d8-3730-4a73-fd3b-6af5e81bdf6d"
      },
      "source": [
        "#@title Prepare training and test data\n",
        "import pandas as pd\n",
        "\n",
        "# Bert Model Constants\n",
        "SEQ_LEN = 128\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 2\n",
        "LR = 2e-5\n",
        "\n",
        "token_dict = {}\n",
        "with codecs.open(vocab_path.replace('\\\\', ''), 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "\n",
        "tokenizer = Tokenizer(token_dict)\n",
        "\n",
        "def load_data(comments, comment_labels):\n",
        "    global tokenizer\n",
        "    indices, labels = [], []\n",
        "    for x in range(comments.shape[0]):\n",
        "      ids, segments = tokenizer.encode(comments[x], max_len=SEQ_LEN)\n",
        "      indices.append(ids)\n",
        "      labels.append(comment_labels[x])\n",
        "\n",
        "    items = list(zip(indices, labels))\n",
        "    np.random.shuffle(items)\n",
        "    indices, labels = zip(*items)\n",
        "    indices = np.array(indices)\n",
        "    mod = indices.shape[0] % BATCH_SIZE\n",
        "    if mod > 0:\n",
        "        indices, labels = indices[:-mod], labels[:-mod]\n",
        "    return [indices, np.zeros_like(indices)], np.array(labels)\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(train_datapath.replace('\\\\', ''))\n",
        "train_df = train_df.sample(frac=0.25,random_state = 42)\n",
        "\n",
        "train_lines = train_df['comment_text'].values\n",
        "labels_ordered = [\n",
        "  'toxic',\n",
        "  'severe_toxic',\n",
        "  'obscene',\n",
        "  'threat',\n",
        "  'insult',\n",
        "  'identity_hate'\n",
        "]\n",
        "train_labels = train_df[labels_ordered].values\n",
        "\n",
        "print('train_lines.shape:', train_lines.shape)\n",
        "print('train_labels.shape:', train_labels.shape)\n",
        "\n",
        "train_x, train_y = load_data(train_lines, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_lines.shape: (39893,)\n",
            "train_labels.shape: (39893, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj3R3iI1h_zq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbc49bc9-da5a-42c2-cd33-f3f64838ace2"
      },
      "source": [
        "# @title Build Custom (Fine-Tuned) Model \n",
        "\n",
        "# Load pretrained model\n",
        "with strategy.scope() if USE_TPU else contextlib.suppress():\n",
        "  model = load_trained_model_from_checkpoint(\n",
        "    config_path.replace('\\\\', ''),\n",
        "    checkpoint_path.replace('\\\\', ''),\n",
        "    training=True,\n",
        "    trainable=True,\n",
        "    seq_len=SEQ_LEN,\n",
        "  )\n",
        "  \n",
        "  # Add dense layer for classification\n",
        "  inputs = model.inputs[:2]\n",
        "  dense = model.get_layer('NSP-Dense').output\n",
        "  outputs = keras.layers.Dense(\n",
        "    units=len(labels_ordered),\n",
        "    activation='sigmoid',\n",
        "    name = 'Toxic-Categories-Dense'\n",
        "  )(dense)\n",
        "  model = keras.models.Model(inputs, outputs)\n",
        "\n",
        "  model.compile(\n",
        "      RAdam(lr=LR),\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f6ba37ee828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f6ba37ee828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f6b9495c128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f6b9495c128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b93669908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b93669908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b936699e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b936699e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b948b7a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b948b7a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b9491d400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b9491d400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9491d048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9491d048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b948ac438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b948ac438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b94941cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b94941cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b936c33c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b936c33c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b936ddeb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b936ddeb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b936ddf28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b936ddf28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b936af240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b936af240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b935f39b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b935f39b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b93566908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b93566908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b936012e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b936012e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9355c128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9355c128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b934f4320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b934f4320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b934eb0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b934eb0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b93453b38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b93453b38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b934490b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b934490b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9342c978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9342c978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b933ccba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b933ccba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b933d8d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b933d8d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b933c4e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b933c4e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b933ba080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b933ba080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9339fa20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9339fa20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b93396a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b93396a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b933097f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b933097f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b932b7940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b932b7940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b932aa0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b932aa0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b93306b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b93306b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b9320ee80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b9320ee80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b9320e278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b9320e278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b931aba20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b931aba20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b93246f60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b93246f60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9317da20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b9317da20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b932016a0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b932016a0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b9312f080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b9312f080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b9309cc50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b9309cc50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b93120940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b93120940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b930e29b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b930e29b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b930ea668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b930ea668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b930eab70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b930eab70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b92f91d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b92f91d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b930129e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b930129e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b92fd1ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b92fd1ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92f7d780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92f7d780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b92f7d748>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b92f7d748>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b92effa20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b92effa20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92f1b0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92f1b0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b92f429e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b92f429e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92eeb7f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92eeb7f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b92edc1d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b92edc1d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b92deda58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b92deda58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92e870b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92e870b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b92e32a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b92e32a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92ddc5f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92ddc5f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b92ddcf28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f6b92ddcf28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b92ce3f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f6b92ce3f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92d169b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92d169b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b92d24cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f6b92d24cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92cace80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92cace80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92d46780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f6b92d46780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method EmbeddingSimilarity.call of <keras_bert.layers.embedding.EmbeddingSimilarity object at 0x7f6b92c5fc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method EmbeddingSimilarity.call of <keras_bert.layers.embedding.EmbeddingSimilarity object at 0x7f6b92c5fc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Masked.call of <keras_bert.layers.masked.Masked object at 0x7f6b954f9b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Masked.call of <keras_bert.layers.masked.Masked object at 0x7f6b954f9b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Extract.call of <keras_bert.layers.extract.Extract object at 0x7f6b92c23080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Extract.call of <keras_bert.layers.extract.Extract object at 0x7f6b92c23080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 23440896    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Toxic-Categories-Dense (Dense)  (None, 6)            4614        NSP-Dense[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,191,942\n",
            "Trainable params: 109,191,942\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi8joUA_iAG0"
      },
      "source": [
        "# @title Initialize Variables\n",
        "\n",
        "sess = K.get_session()\n",
        "uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
        "init_op = tf.variables_initializer(\n",
        "    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
        ")\n",
        "sess.run(init_op)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok1LvFpAiAac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f3b61e4b-7fd8-4b88-a154-9d2216f2c16c"
      },
      "source": [
        "# @title Train\n",
        "history = model.fit(\n",
        "    train_x,\n",
        "    train_y,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.33,\n",
        "    shuffle=True,\n",
        ")\n",
        "model.save('toxic_comment_classif_50perc.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 26724 samples, validate on 13164 samples\n",
            "Epoch 1/2\n",
            "26724/26724 [==============================] - 1251s 47ms/sample - loss: 0.0858 - acc: 0.9660 - val_loss: 0.0450 - val_acc: 0.9822\n",
            "Epoch 2/2\n",
            "26724/26724 [==============================] - 1235s 46ms/sample - loss: 0.0404 - acc: 0.9845 - val_loss: 0.0431 - val_acc: 0.9827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a61jZciKiAtb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "8145e6e4-3334-4f46-a849-1c93241b4b33"
      },
      "source": [
        "#@title Plot model training progress\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "%matplotlib inline\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_FyhoMoiBok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "b3dc8324-9599-4c79-9b4a-11d8de19f291"
      },
      "source": [
        "#@title Classifying texts\n",
        "texts = [\n",
        "  'You are an idiot!',\n",
        "  'You are a  drug addict!',\n",
        "  'I will kill you!',\n",
        "  'I want to goto London',\n",
        "  'You must create a model which predicts a probability of each type of toxicity for each comment.',\n",
        "  'He was sad, his grand-parent got killed in a car accident!',\n",
        "  'You stupid jackass! I will kill you.'\n",
        "\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "  ids, segments = tokenizer.encode(text, max_len=SEQ_LEN)\n",
        "  inpu = np.array(ids).reshape([1, SEQ_LEN])\n",
        "  predicted = (model.predict([inpu,np.zeros_like(inpu)]) >= 0.5).astype(int)\n",
        "  print (\"%s: %s\"%\n",
        "    (\n",
        "      text,\n",
        "      [\n",
        "        label\n",
        "        for i, label in enumerate(labels_ordered)\n",
        "        if predicted[0][i]\n",
        "      ]\n",
        "    )\n",
        "  )\n",
        "\n",
        "print('\\n')\n",
        "print (labels_ordered)\n",
        "for text in texts:\n",
        "  ids, segments = tokenizer.encode(text, max_len=SEQ_LEN)\n",
        "  inpu = np.array(ids).reshape([1, SEQ_LEN])\n",
        "  predicted = model.predict([inpu,np.zeros_like(inpu)])\n",
        "  print (\"%s: %s\"% (predicted, text))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are an idiot!: ['toxic', 'obscene', 'insult']\n",
            "You are a  drug addict!: ['toxic']\n",
            "I will kill you!: ['toxic', 'threat']\n",
            "I want to goto London: []\n",
            "You must create a model which predicts a probability of each type of toxicity for each comment.: []\n",
            "He was sad, his grand-parent got killed in a car accident!: []\n",
            "You stupid jackass! I will kill you.: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult']\n",
            "\n",
            "\n",
            "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "[[0.9944135  0.07509044 0.68364394 0.01582807 0.96309525 0.06323443]]: You are an idiot!\n",
            "[[0.8957073  0.00888687 0.07954308 0.01142967 0.47257832 0.05919608]]: You are a  drug addict!\n",
            "[[0.95645237 0.2514637  0.21216995 0.75382674 0.28388628 0.08687323]]: I will kill you!\n",
            "[[0.00077209 0.00016513 0.00066075 0.00021815 0.00048605 0.00021631]]: I want to goto London\n",
            "[[0.00075552 0.00019819 0.00039548 0.00019068 0.0005849  0.00022588]]: You must create a model which predicts a probability of each type of toxicity for each comment.\n",
            "[[0.02153319 0.00026706 0.00162226 0.00082991 0.00334463 0.00059395]]: He was sad, his grand-parent got killed in a car accident!\n",
            "[[0.9980347  0.5859896  0.84743285 0.6677285  0.8729268  0.16893505]]: You stupid jackass! I will kill you.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL6d_TNyORS_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}